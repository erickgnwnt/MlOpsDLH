{"CV Score Std Dev":0.0701560760020114,"Training Accuracy":0.88125,"CV Fold 5 Score":0.875,"CV Fold 1 Score":0.875,"Test Accuracy":0.9512195121951219,"Classification Report":{"0.0":{"f1-score":0.9333333333333333,"support":7,"precision":0.875,"recall":1},"1.0":{"f1-score":0.9696969696969697,"support":16,"precision":0.9411764705882353,"recall":1},"2.0":{"precision":1,"recall":0.8888888888888888,"f1-score":0.9411764705882353,"support":18},"accuracy":0.9512195121951219,"macro avg":{"recall":0.9629629629629629,"f1-score":0.9480689245395127,"support":41,"precision":0.9387254901960785},"weighted avg":{"f1-score":0.9509673492456848,"support":41,"precision":0.9557030129124822,"recall":0.9512195121951219}},"C":100,"Training Time (seconds)":17.144535064697266,"_wandb":{"runtime":18},"Solver":{"artifact_path":"wandb-client-artifact://tq80tyvttnj7szi5kx6rc729iculmt6f0pg9imv53ki4c4t4f4ed1e03edk76fn8tipshxddquf2ftrx07sm6jo3axenu98on2xj51t66th84kdlii59juinv253s567/Solver.table.json","_latest_artifact_path":"wandb-client-artifact://2atjl8whw41a10mmdi866oagkdcildqsyt40883mq4i355n55ofpw0gawm7lwlodqq9zsncczp925k8a22ko32nzbnojkubjqmdb0upqihpqfsddf9c9nbejwkgpn2wh:latest/Solver.table.json","path":"media/table/Solver_44_452da4a78c4b28a0ff54.table.json","ncols":1,"nrows":1,"_type":"table-file","sha256":"452da4a78c4b28a0ff54ae42a31cd0b75e5745ee9cb90d7fa2b6c1a9c3e2be24","size":48},"CV Fold 2 Score":0.71875,"_step":53,"CV Score Mean":0.83125,"_runtime":18.4085566,"Max Iter":10000,"CV Fold 3 Score":0.78125,"_timestamp":1.7488379000695033e+09,"Validation Accuracy":0.83125,"CV Fold 4 Score":0.90625}